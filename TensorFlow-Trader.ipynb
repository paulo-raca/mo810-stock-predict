{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import scipy.stats\n",
    "import typing\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import softops\n",
    "import tensorboard\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingState:\n",
    "    def __init__(self, money: tf.Tensor, stocks: tf.Tensor, stock_prices: tf.Tensor, inner_state: typing.Any = None, money_value: tf.Tensor = None, stocks_value: tf.Tensor = None, account_value: tf.Tensor = None):\n",
    "        self.money = tf.identity(money, name='money')\n",
    "        self.stocks = tf.identity(stocks, name='stocks')\n",
    "        self.stock_prices = tf.identity(stock_prices, name='stock_prices')\n",
    "        self.inner_state = inner_state\n",
    "\n",
    "        if money_value is not None:\n",
    "            self.money_value = tf.identity(money_value, name='money_value')\n",
    "        else:\n",
    "            self.money_value = tf.reduce_sum(self.money, axis=1, name='money_value')\n",
    "            \n",
    "        if stocks_value is not None:\n",
    "            self.stocks_value = tf.identity(stocks_value, name='stocks_value')\n",
    "        else:\n",
    "            self.stocks_value = tf.reduce_sum(self.stocks*self.stock_prices, axis=1, name='stocks_value')\n",
    "            \n",
    "        if account_value is not None:\n",
    "            self.account_value = tf.identity(account_value, name='account_value')\n",
    "        else:\n",
    "            self.account_value = tf.add(self.money_value, self.stocks_value, name='account_value')\n",
    "\n",
    "    def copy(self, **kwargs):\n",
    "        args = dict(\n",
    "            money = self.money,\n",
    "            stocks = self.stocks,\n",
    "            stock_prices = self.stock_prices,\n",
    "            inner_state = self.inner_state,\n",
    "            money_value = self.money_value,\n",
    "            stocks_value = self.stocks_value,\n",
    "            account_value = self.account_value)\n",
    "        args.update(kwargs)\n",
    "        return TradingState(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LOW    = 0\n",
    "FEATURE_HIGH   = 1\n",
    "FEATURE_OPEN   = 2\n",
    "FEATURE_CLOSE  = 3\n",
    "FEATURE_VOLUME = 4\n",
    "\n",
    "RESPONSE_BUY_PRICE   = 0\n",
    "RESPONSE_BUY_AMOUNT  = 1\n",
    "RESPONSE_SELL_LOW    = 2\n",
    "RESPONSE_SELL_HIGH   = 3\n",
    "\n",
    "MONEY_TODAY = 0\n",
    "MONEY_TOMORROW = 1\n",
    "\n",
    "SELL_TRANSACTION_COST = 5 # 5 USD per transaction\n",
    "BUY_TRANSACTION_COST = 5  # 5 USD per transaction\n",
    "\n",
    "def trader_builder(historic_window_size, trainable_variables_node):    \n",
    "    with trainable_variables_node:\n",
    "        coef_buy_price  = tf.Variable(tf.zeros([historic_window_size, 4]), name=\"buy_coefs\")\n",
    "        coef_sell_price = tf.Variable(tf.zeros([historic_window_size, 4]), name=\"sell_coefs\")\n",
    "        coef_bias = tf.Variable([-1.,+1.], name=\"biases\")\n",
    "        \n",
    "    first_inner_state = tf.constant([1,2,3])\n",
    "        \n",
    "    def build_trader(state: TradingState, historic_data: tf.Tensor, inner_state: typing.Any) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Builds the trader network on tensorflow\n",
    "\n",
    "        Arguments:\n",
    "        - state: Trading state coming from the previous day\n",
    "        - historic_data: tensor[minibatch, time, company] -> [low, high, open, close]\n",
    "\n",
    "        Returns: \n",
    "        tensor[minibatch, company] -> [buy_price, buy_amount, sell_low_price, sell_high_price]\n",
    "        - buy_price: The price for which you want to buy stocks\n",
    "        - buy_amount: Fraction of the cash available to be used to buy stocks from this company (If the price target is reached)\n",
    "        - sell_high_price: If the stock price reaches more than this amount, all of the owned stocks will be sold (Ideal case, sell when the price is high)\n",
    "        - sell_low_price: If the stock price reaches less than this amount, all of the owned stocks will also be sold (Fucked up case: Prices are crashing, minimize losses)\n",
    "        \"\"\"\n",
    "        with tf.name_scope('normalize_input'):\n",
    "            normalize_factor = tf.concat(\n",
    "                [\n",
    "                    tf.expand_dims(historic_data[:, 0, :, FEATURE_OPEN ], 1),\n",
    "                    historic_data[:, :-1, :, FEATURE_CLOSE],\n",
    "                ],\n",
    "                axis = 1,\n",
    "                name = 'factor'\n",
    "            )\n",
    "            normalized_history = tf.multiply(\n",
    "                100., \n",
    "                tf.log( historic_data[:,:,:,:-1] / normalize_factor[:, :, :, tf.newaxis]), \n",
    "                name='normalized_history'\n",
    "            )\n",
    "        \n",
    "        with tf.name_scope('buy_price'):\n",
    "            buy_price = coef_bias[0] + tf.reduce_sum(normalized_history * coef_buy_price[tf.newaxis, :, tf.newaxis, :], axis=[1,3])\n",
    "        with tf.name_scope('buy_amount'):\n",
    "            buy_amount = tf.fill(tf.shape(buy_price), value=0.1)\n",
    "        with tf.name_scope('sell_low_price'):\n",
    "            sell_low_price = tf.fill(tf.shape(buy_price), value=-9999.)  # Never!\n",
    "        with tf.name_scope('sell_high_price'):\n",
    "            sell_high_price = coef_bias[1] + tf.reduce_sum(normalized_history * coef_sell_price[tf.newaxis, :, tf.newaxis, :], axis=[1,3])\n",
    "\n",
    "        with tf.name_scope('denormalize_prices'):\n",
    "            def denorm(x, name=None):\n",
    "                return tf.multiply(tf.exp(x / 100), historic_data[:, -1, :, FEATURE_CLOSE], name = name)\n",
    "            buy_price = denorm(buy_price, 'buy_price')\n",
    "            sell_low_price = denorm(sell_low_price, 'sell_low_price')\n",
    "            sell_high_price = denorm(sell_high_price, 'sell_high_price')\n",
    "            \n",
    "        with tf.name_scope('result'):\n",
    "            result = tf.stack([buy_price, buy_amount, sell_low_price, sell_high_price], axis=2)\n",
    "            return (result, inner_state)\n",
    "        \n",
    "    return build_trader, first_inner_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env_step(build_trader, state: TradingState, historic_data: tf.Tensor, next_day_data: tf.Tensor) -> TradingState:\n",
    "    \"\"\"\n",
    "    Builds a single-day trading environment.\n",
    "    Arguments:\n",
    "    - state: Trading state coming from the previous day\n",
    "    - historic_data: tensor[minibatch, time, company] -> [low, high, open, close]\n",
    "    - next_day_data: tensor[minibatch, company] -> [low, high, open, close]\n",
    "\n",
    "    \n",
    "    Returns: The next state, computed at the end of the next trading day\n",
    "    \"\"\"   \n",
    "    with tf.name_scope(\"trader\"):\n",
    "        trader, new_inner_state = build_trader(state = state, historic_data = historic_data, inner_state = state.inner_state)\n",
    "       \n",
    "        \n",
    "    with tf.name_scope(\"simulator\"):\n",
    "        softness = 1\n",
    "        \n",
    "        with tf.name_scope(\"slicing\"):\n",
    "            buy_price       = trader[:,:, RESPONSE_BUY_PRICE]\n",
    "            buy_amount      = trader[:,:, RESPONSE_BUY_AMOUNT]\n",
    "            sell_low_price  = trader[:,:, RESPONSE_SELL_LOW]\n",
    "            sell_high_price = trader[:,:, RESPONSE_SELL_HIGH]\n",
    "            current_money   = state.money[:, MONEY_TODAY]\n",
    "            current_stocks  = state.stocks\n",
    "            eod_stock_prices = next_day_data[:, :, FEATURE_CLOSE]\n",
    "\n",
    "        # Executes SELL transactions if prices reaches BELOW a threshold (minimize losses)            \n",
    "        # (If the day opens below the threshold for LOW SELL, use the open price)\n",
    "        with tf.name_scope(\"sell_low\"):\n",
    "            sell_low_price = tf.identity(\n",
    "                sell_low_price,\n",
    "                name='order_price')\n",
    "            sell_low_price = tf.minimum(\n",
    "                next_day_data[:, :, FEATURE_OPEN],\n",
    "                sell_low_price, \n",
    "                name = 'actual_price')\n",
    "            sell_low_amount = tf.identity(\n",
    "                current_stocks,\n",
    "                name = 'order_amount')\n",
    "            sell_low_kernel = tf.multiply(\n",
    "                softops.gte(sell_low_price, next_day_data[:, :, FEATURE_LOW], percent = True, softness = softness),\n",
    "                softops.positive(sell_low_amount),\n",
    "                name = 'order_executed')\n",
    "                \n",
    "            sell_low_stock_bough = tf.zeros(tf.shape(sell_low_kernel), name='stock_bought')\n",
    "            sell_low_stock_sold = tf.multiply(sell_low_kernel, sell_low_amount, name='stock_sold')\n",
    "            money_earned_sell_low = tf.reduce_sum(sell_low_stock_sold * sell_low_price, axis=1, name='money_earned')\n",
    "            money_spent_sell_low = tf.reduce_sum(sell_low_kernel * SELL_TRANSACTION_COST, axis=1, name='money_spent')\n",
    "\n",
    "        # Executes SELL transactions if prices reaches ABOVE a threshold (Maximize gains)\n",
    "        with tf.name_scope(\"sell_high\"):\n",
    "            sell_high_price = tf.identity(\n",
    "                sell_high_price,\n",
    "                name='order_price')\n",
    "            sell_high_price = tf.identity(\n",
    "                sell_high_price,\n",
    "                name='actual_price')\n",
    "            sell_high_amount = tf.identity(\n",
    "                current_stocks - sell_low_stock_sold,\n",
    "                name = 'order_amount')\n",
    "            sell_high_kernel = tf.multiply(\n",
    "                softops.lte(sell_high_price, next_day_data[:, :, FEATURE_HIGH], percent = True, softness = softness),\n",
    "                softops.positive(sell_high_amount),\n",
    "                name = 'order_executed')\n",
    "                \n",
    "            sell_high_stock_bough = tf.zeros(tf.shape(sell_high_kernel), name='stock_bought')\n",
    "            sell_high_stock_sold = tf.multiply(sell_high_kernel, sell_high_amount, name='stock_sold')\n",
    "            money_earned_sell_high = tf.reduce_sum(sell_high_stock_sold * sell_high_price, axis=1, name='money_earned')\n",
    "            money_spent_sell_high = tf.reduce_sum(sell_high_kernel * SELL_TRANSACTION_COST, axis=1, name='money_spent')\n",
    "\n",
    "        # Executes BUY transactions if prices reaches above a threshold\n",
    "        # (Normalize `buy_amount` to be in amount of stocks, instead of fraction of my money)\n",
    "        with tf.name_scope(\"buy\"):\n",
    "            buy_price = tf.identity(\n",
    "                buy_price,\n",
    "                name = 'order_price')\n",
    "            buy_price = tf.identity(\n",
    "                buy_price,\n",
    "                name = 'actual_price')\n",
    "            buy_amount = softops.floor(\n",
    "                buy_amount * current_money[:, tf.newaxis] / buy_price,\n",
    "                name = 'order_amount')\n",
    "            buy_kernel = tf.multiply(\n",
    "                softops.gte(buy_price, next_day_data[:, :, FEATURE_LOW], percent = True, softness = softness),\n",
    "                softops.positive(buy_amount),\n",
    "                name='kernel')\n",
    "                \n",
    "            buy_stock_bough = tf.multiply(buy_kernel, buy_amount, name='stock_sold')\n",
    "            buy_stock_sold = tf.zeros(tf.shape(buy_kernel), name='stock_bought')\n",
    "            money_earned_buy = tf.zeros(tf.shape(current_money), name='money_earned')\n",
    "            money_spent_buy = tf.reduce_sum(buy_stock_bough * buy_price + buy_kernel * BUY_TRANSACTION_COST, axis=1, name='money_spent')\n",
    "\n",
    "        with tf.name_scope(\"update_money\"):           \n",
    "            total_money_earned = money_earned_sell_high + money_earned_sell_low + money_earned_buy\n",
    "            total_money_spent = money_spent_sell_low + money_spent_sell_high + money_spent_buy\n",
    "            new_money_first = tf.expand_dims(current_money - total_money_spent + state.money[:, MONEY_TOMORROW], axis = 1)\n",
    "            new_money_middle = state.money[:, 2:]\n",
    "            new_money_last = tf.expand_dims(total_money_earned, axis = 1)\n",
    "            \n",
    "            next_money = tf.concat([\n",
    "                new_money_first,\n",
    "                new_money_middle,\n",
    "                new_money_last\n",
    "            ], axis = 1)\n",
    "\n",
    "            with tf.name_scope(\"money_earned\"):\n",
    "                tf.summary.histogram('values', total_money_earned)\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(total_money_earned))\n",
    "            with tf.name_scope(\"money_spent\"):\n",
    "                tf.summary.histogram('values', total_money_spent)\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(total_money_spent))\n",
    "            with tf.name_scope(\"money_delta\"):\n",
    "                tf.summary.histogram('values', total_money_earned - total_money_spent)\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(total_money_earned - total_money_spent))\n",
    "            with tf.name_scope(\"money_final\"):\n",
    "                tf.summary.histogram('values', tf.reduce_sum(next_money, axis=1))\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(tf.reduce_sum(next_money, axis=1)))\n",
    "\n",
    "        with tf.name_scope(\"update_stocks\"):\n",
    "            total_stocks_bought = sell_low_stock_bough + sell_high_stock_bough + buy_stock_bough\n",
    "            total_stocks_sold = sell_low_stock_sold + sell_high_stock_sold + buy_stock_sold\n",
    "            next_stocks = current_stocks + total_stocks_bought - total_stocks_sold\n",
    "            next_stocks_value = tf.reduce_sum(next_stocks * eod_stock_prices, axis=1)\n",
    "            \n",
    "#             with tf.name_scope(\"stocks_bought\"):\n",
    "#                 tf.summary.histogram('values', total_stocks_bought)\n",
    "#                 tf.summary.scalar('mean', tf.reduce_mean(total_stocks_bought))\n",
    "#             with tf.name_scope(\"stocks_sold\"):\n",
    "#                 tf.summary.histogram('values', total_stocks_sold)\n",
    "#                 tf.summary.scalar('mean', tf.reduce_mean(total_stocks_sold))\n",
    "#             with tf.name_scope(\"stocks_delta\"):\n",
    "#                 tf.summary.histogram('values', total_stocks_bought - total_stocks_sold)\n",
    "#                 tf.summary.scalar('mean', tf.reduce_mean(total_stocks_bought - total_stocks_sold))\n",
    "#             with tf.name_scope(\"stocks_final\"):\n",
    "#                 tf.summary.histogram('values', next_stocks)\n",
    "#                 tf.summary.scalar('mean', tf.reduce_mean(next_stocks))\n",
    "            with tf.name_scope(\"stocks_value_final\"):\n",
    "                tf.summary.histogram('values', next_stocks_value)\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(next_stocks_value))\n",
    "            with tf.name_scope(\"stocks_value_delta\"):\n",
    "                tf.summary.histogram('values', next_stocks_value - state.stocks_value)\n",
    "                tf.summary.scalar('mean', tf.reduce_mean(next_stocks_value - state.stocks_value))\n",
    "    \n",
    "        return dict(\n",
    "            money = next_money,\n",
    "            stocks = next_stocks,\n",
    "            stock_prices = eod_stock_prices,\n",
    "            stocks_value= next_stocks_value,\n",
    "            inner_state = new_inner_state\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_env(trainable_variables_node, historic_data, initial_state, num_days, historic_window_size):    \n",
    "    build_trader, first_inner_state = trader_builder(historic_window_size, trainable_variables_node)\n",
    "    \n",
    "    with tf.name_scope(f'state_0'):\n",
    "        current_state = TradingState(inner_state = first_inner_state, **initial_state)\n",
    "    all_states = [current_state]\n",
    "    \n",
    "        \n",
    "    for i in range(num_days):\n",
    "        #print(f'day_{i}')\n",
    "        with tf.name_scope(f'day_{i}'):\n",
    "            with tf.name_scope(f'historic_data'):\n",
    "                historic_slice = historic_data[:, i:i+historic_window_size, : ,:]\n",
    "            with tf.name_scope(f'next_day_data'):\n",
    "                next_day_slice = historic_data[:, i+historic_window_size, : ,:]\n",
    "\n",
    "            current_state = build_env_step(\n",
    "                build_trader = build_trader,\n",
    "                state = current_state,\n",
    "                historic_data = historic_slice,\n",
    "                next_day_data = next_day_slice\n",
    "            )\n",
    "            \n",
    "        with tf.name_scope(f'state_{i+1}'):\n",
    "            current_state = TradingState(**current_state)\n",
    "\n",
    "        all_states.append(current_state)\n",
    "    return all_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(warmup_days = 5, evaluated_days = 20, historic_window_size = 5, money_settle_time = 3, check_numerics = False) -> tf.Graph:\n",
    "    total_days = evaluated_days + warmup_days + historic_window_size\n",
    "    \n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():        \n",
    "        trainable_variables_node = tf.name_scope(\"trainable_parameters\")\n",
    "        iteration = tf.Variable(0, name='iteration', dtype=tf.int32, expected_shape=())\n",
    "                    \n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            stock_history = tf.placeholder(tf.float32, shape=(None, total_days, None, 5), name=\"stock_history\")\n",
    "\n",
    "            minibatch_size = tf.shape(stock_history)[0]\n",
    "            num_companies = tf.shape(stock_history)[2]    \n",
    "            default_initial_stocks = tf.zeros([minibatch_size, num_companies], name = 'default_initial_stocks')\n",
    "            initial_stocks = tf.placeholder_with_default(default_initial_stocks, shape = (None, None), name = 'initial_stocks')\n",
    "\n",
    "            initial_money_simple = tf.placeholder_with_default(10000., shape = (), name = 'initial_money_simple')\n",
    "            default_initial_money = tf.concat(\n",
    "                [\n",
    "                    initial_money_simple * tf.ones([minibatch_size, 1]),\n",
    "                    tf.zeros([minibatch_size, money_settle_time-1])\n",
    "                ], \n",
    "                axis = 1,\n",
    "                name = 'default_initial_money')\n",
    "            initial_money = tf.placeholder_with_default(default_initial_money, shape = (None, money_settle_time), name = 'initial_money')\n",
    "            \n",
    "            with tf.name_scope(\"initial_state\"):\n",
    "                initial_state = dict(\n",
    "                    money = initial_money,\n",
    "                    stocks = initial_stocks,\n",
    "                    stock_prices = stock_history[:, historic_window_size - 1, :, FEATURE_CLOSE],\n",
    "                )\n",
    "\n",
    "        with tf.name_scope(\"trading\"):\n",
    "            all_states = build_env(trainable_variables_node, stock_history, initial_state, warmup_days + evaluated_days, historic_window_size)\n",
    "            initial_account_value = all_states[0].account_value\n",
    "\n",
    "        with tf.name_scope(\"evaluation\"):\n",
    "            with tf.name_scope(\"account_values\"):\n",
    "                account_values = tf.stack([\n",
    "                    all_states[i].account_value\n",
    "                    for i in range(warmup_days, warmup_days + evaluated_days + 1)\n",
    "                ], axis = 1, name = 'values')\n",
    "            with tf.name_scope(\"daily_variation\"):\n",
    "                daily_variation = tf.div(account_values[:, 1:], account_values[:, :-1], name = \"values\")\n",
    "            with tf.name_scope(\"normalized_daily_variation\"):\n",
    "                normalized_daily_variation = tf.multiply(100., tf.log(daily_variation), name = \"values\")\n",
    "            \n",
    "            with tf.name_scope(\"summaries\"):\n",
    "                with tf.name_scope(\"daily_variation\"):\n",
    "                    tf.summary.histogram('values', tf.clip_by_value(normalized_daily_variation, -10, +10, name='values'))\n",
    "                    tf.summary.scalar('mean', tf.reduce_mean(normalized_daily_variation, name='mean'))\n",
    "                with tf.name_scope(\"final_account_value\"):\n",
    "                    tf.summary.histogram('values', tf.clip_by_value(all_states[-1].account_value, 0, 2*initial_account_value, name='values'))\n",
    "                    tf.summary.scalar('mean', tf.reduce_mean(all_states[-1].account_value, name='mean'))\n",
    "                with tf.name_scope(\"final_money\"):\n",
    "                    tf.summary.histogram('values', tf.clip_by_value(all_states[-1].money_value, 0, 2*initial_account_value, name='values'))\n",
    "                    tf.summary.scalar('mean', tf.reduce_mean(all_states[-1].money_value, name='mean'))\n",
    "                with tf.name_scope(\"final_stocks_value\"):\n",
    "                    tf.summary.histogram('values', tf.clip_by_value(all_states[-1].stocks_value, 0, 2*initial_account_value, name='values'))\n",
    "                    tf.summary.scalar('mean', tf.reduce_mean(all_states[-1].stocks_value, name='mean'))\n",
    "                \n",
    "        if check_numerics:\n",
    "            tf.add_check_numerics_ops()\n",
    "    return graph    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph = build_graph(check_numerics=True)\n",
    "tensorboard.show_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset/dataset-2017-10-11\"\n",
    "STOCK_DIR = f\"{DATASET_DIR}/Stocks\"\n",
    "ETF_DIR = f\"{DATASET_DIR}/ETFs\"\n",
    "\n",
    "sp500 = pd.read_csv('dataset/s&p500.tsv', sep='\\t')['Ticker symbol']\n",
    "\n",
    "def concat_datasets(datasets):\n",
    "    return pd.concat(\n",
    "        df.assign(Symbol = symbol)\n",
    "        for symbol, df in datasets.items()\n",
    "    )\n",
    "\n",
    "def dataset_to_timeseries(df, days):\n",
    "    \"\"\"\n",
    "    Concatenates `days` sequential values to create a larger feature array.\n",
    "    \"\"\"\n",
    "    parallel_series = [\n",
    "        df[d:len(df)+1-days+d]\n",
    "        for d in reversed(range(days))\n",
    "    ]\n",
    "    \n",
    "    cols = ['Date']\n",
    "    data = [parallel_series[0].Date]\n",
    "    for i in range(len(parallel_series)):\n",
    "        s = parallel_series[i]\n",
    "        for col in ['Open', 'Close', 'High', 'Low', 'Volume']:\n",
    "            cols.append(f'{col}.{i}')\n",
    "            data.append(s[col])\n",
    "            \n",
    "    return pd.DataFrame(list(zip(*data)), columns=cols)\n",
    "\n",
    "def split_dataset_by_date(dataset, test_size = 0.2):\n",
    "    trading_dates = sorted(set(dataset.Date))\n",
    "    train_dates, test_dates = train_test_split(trading_dates, test_size=test_size)\n",
    "    train_dataset = dataset[dataset.Date.isin(set(train_dates))].sample(frac=1).reset_index(drop=True)\n",
    "    test_dataset = dataset[dataset.Date.isin(set(test_dates))].sample(frac=1).reset_index(drop=True)\n",
    "    return (train_dataset, test_dataset)\n",
    "\n",
    "def extract_all_data(symbols, feature_days=30, min_date='1990-01-01'):\n",
    "    symbols = set(symbols)\n",
    "    failed_csvs = []\n",
    "    raw_data = {}\n",
    "    timeseries_feature_data = {}\n",
    "    for filename in os.listdir(STOCK_DIR):\n",
    "        symbol = filename.split('.')[0].upper()\n",
    "        if not symbol in symbols:\n",
    "            continue\n",
    "\n",
    "        raw = pd.read_csv(f\"{STOCK_DIR}/{filename}\")\n",
    "        raw_data[symbol] = raw[raw.Date >= min_date]\n",
    "        timeseries_feature_data[symbol] = dataset_to_timeseries(raw_data[symbol], feature_days)\n",
    "\n",
    "        #if len(raw_data) > 5:\n",
    "            #break\n",
    "            \n",
    "    if failed_csvs:\n",
    "        logging.warning(f'Failed to read {len(failed_csvs)} CSV files: {failed_csvs}')\n",
    "            \n",
    "    all_samples = concat_datasets(timeseries_feature_data)\n",
    "    train_samples, test_samples = split_dataset_by_date(all_samples)\n",
    "    return train_samples, test_samples\n",
    "\n",
    "def create_minibatch(dataset, minibatch_size, num_companies):\n",
    "    minibatch = []\n",
    "    for i in range(minibatch_size):\n",
    "        date = random.choice(dataset.Date)\n",
    "        dataset_at_date = dataset[dataset.Date == date]\n",
    "\n",
    "        samples = dataset_at_date.sample(n = num_companies, replace = True)\n",
    "        samples = samples.as_matrix(columns=samples.columns[1:-1])\n",
    "        samples = samples.reshape([num_companies, -1, 5])\n",
    "        samples = samples.transpose((1,0,2))\n",
    "        minibatch.append(samples)\n",
    "    return np.stack(minibatch)\n",
    "    \n",
    "def minibatch_producer(symbols, feature_days=30, min_date='2013-01-01', minibatch_size=10, num_companies=10):\n",
    "    all_data = extract_all_data(symbols, feature_days=feature_days, min_date=min_date)\n",
    "    def produce(train=True, minibatch_size=minibatch_size, num_companies=num_companies):\n",
    "        return create_minibatch(dataset=all_data[0 if train else 1], minibatch_size=minibatch_size, num_companies=num_companies)\n",
    "    return produce\n",
    "\n",
    "companies = ['GOOG', 'AMZN', 'NFLX', 'TSLA', 'FB', 'AAPL', 'INTC', 'QCOM', 'DIS', 'NVDA'] #sp500\n",
    "next_minibatch = minibatch_producer(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with build_graph(check_numerics = True).as_default():\n",
    "    checkpoint_file = os.path.abspath(f'checkpoint/trader.ckpt')\n",
    "    tensorboard_dir = os.path.abspath('tensorboard_logs')\n",
    "    tensorboard_run = datetime.utcnow().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    tensorboard_run_dir = f'{tensorboard_dir}/{tensorboard_run}'\n",
    "    os.makedirs(os.path.dirname(checkpoint_file), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(tensorboard_run_dir), exist_ok=True)\n",
    "    \n",
    "    input_stock_history = tf.get_default_graph().get_tensor_by_name('inputs/stock_history:0')\n",
    "    input_initial_money = tf.get_default_graph().get_tensor_by_name('inputs/initial_money_simple:0')\n",
    "\n",
    "    iteration = tf.get_default_graph().get_tensor_by_name('iteration:0')\n",
    "    \n",
    "    buy_coefs = tf.get_default_graph().get_tensor_by_name('trading/trainable_parameters/buy_coefs:0')\n",
    "    sell_coefs = tf.get_default_graph().get_tensor_by_name('trading/trainable_parameters/sell_coefs:0')\n",
    "    \n",
    "    evaluation_normalized_profit = tf.get_default_graph().get_tensor_by_name('evaluation/summaries/daily_variation/values:0')\n",
    "    evaluation_normalized_profit_mean = tf.get_default_graph().get_tensor_by_name('evaluation/summaries/daily_variation/mean:0')\n",
    "    all_summaries = tf.summary.merge_all()                 \n",
    "    \n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=0.0005, momentum=0.9, use_nesterov=True)\n",
    "    training_op = optimizer.minimize(-evaluation_normalized_profit_mean, global_step = iteration)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    with tf.summary.FileWriter(tensorboard_run_dir, tf.get_default_graph()) as tensorboard_writer:    \n",
    "        display(tensorboard.Server.of(tensorboard_dir).badge(run=tensorboard_run))\n",
    "\n",
    "        with tf.Session() as session:\n",
    "            tf.add_check_numerics_ops()\n",
    "            tf.global_variables_initializer().run()\n",
    "            try:\n",
    "                #saver.restore(session, checkpoint_file)\n",
    "                pass\n",
    "            except:\n",
    "                logging.warning(f'Failed to restore training state from {checkpoint_file}')\n",
    "                raise\n",
    "                \n",
    "            last_checkout = time.time() - 1\n",
    "            while True:\n",
    "                now = time.time()\n",
    "                if (now - last_checkout) >= 1:\n",
    "                    last_checkout = now\n",
    "                    saver.save(session, checkpoint_file)\n",
    "                    \n",
    "                    #print([iteration, evaluation_normalized_profit, all_summaries])\n",
    "                    test_params = {\n",
    "                        tf.get_default_graph().get_tensor_by_name('inputs/stock_history:0'): next_minibatch(train=False, minibatch_size=100, num_companies=10),\n",
    "                        tf.get_default_graph().get_tensor_by_name('inputs/initial_money_simple:0'): 50000\n",
    "                    }\n",
    "                    result = session.run([iteration, evaluation_normalized_profit, all_summaries], feed_dict=test_params)\n",
    "                    i = result[0]\n",
    "                    normalized_evaluation_values = result[1]\n",
    "                    summaries = result[2]\n",
    "                                \n",
    "                    print(f'Epoch [{i}] -- trader_evaluation: {normalized_evaluation_values.mean():.2f}±{normalized_evaluation_values.std():.2f} %/day')\n",
    "                    tensorboard_writer.add_summary(summaries, i)\n",
    "\n",
    "                train_params = {\n",
    "                    tf.get_default_graph().get_tensor_by_name('inputs/stock_history:0'): next_minibatch(train=True, minibatch_size=1, num_companies=10),\n",
    "                    tf.get_default_graph().get_tensor_by_name('inputs/initial_money_simple:0'): 50000\n",
    "                }\n",
    "                session.run(training_op, feed_dict=train_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
